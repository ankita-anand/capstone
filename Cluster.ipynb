{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from embedder import Embedder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import json\n",
    "import spacy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "FOR DATA MANIPULATION ONLY.\n",
    "\n",
    "data = json.load(open('data/wikidata2.json'))\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df.columns = ['Text']\n",
    "df['Length'] = df.Text.apply(len)\n",
    "df = df.reset_index()\n",
    "df.columns = ['Concept', 'Text', 'Length']\n",
    "df = df.sort_values('Length')[::-1]\n",
    "df = df.reset_index()\n",
    "df = df.drop(columns=['index'])\n",
    "df = df.drop([0,1,2,3,4,5])\n",
    "df = df.reset_index()\n",
    "df = df.drop(columns=['index'])\n",
    "\n",
    "concepts = df.Concept.values.tolist()\n",
    "text = df.Text.values.tolist()\n",
    "df['Intro'] = df.Concept.apply(lambda x: '#' not in x)\n",
    "\n",
    "introlen = df[df.Intro].Text.apply(lambda x: x.split(' ')).apply(len)\n",
    "sectlen = df[~df.Intro].Text.apply(lambda x: x.split(' ')).apply(len)\n",
    "\n",
    "print(introlen.max(), introlen.mean(), sectlen.max(), sectlen.mean())\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "introlen.hist(bins=50)\n",
    "sectlen.hist(bins=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DO NOT RUN\n",
    "sections = pd.read_csv('data/sections.csv')\n",
    "discard = sections[sections.Keep == 'n']\n",
    "discard = set(discard.Concept.values)\n",
    "df['Keep'] = df.Concept.apply(lambda x: x not in discard)\n",
    "df = df[df.Keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making of final data-set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DO NOT RUN\n",
    "df['FixedText'] = df.Text.apply(lambda x: x[2:-1])\n",
    "df['Data'] = df.FixedText.apply(lambda x: ' '.join(x.split(' ')[:150]))\n",
    "df[['Concept', 'Data']]\n",
    "df.to_csv('data/wikidata2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Embedder and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = Embedder()\n",
    "df = pd.read_csv('data/wikidata2.csv')\n",
    "df = df.sort_values('Length')[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate embeddings for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN ONLY TO CREATE NEW EMBEDDINGS\n",
    "\n",
    "text = df.Data.values.tolist()\n",
    "embeddings = []\n",
    "preprocessed = embedder.preprocess(text)\n",
    "tokenized = embedder.doc_tokenize(preprocessed)\n",
    "batch_size = 8\n",
    "for i in tqdm.trange(0,len(df),batch_size):\n",
    "    embeddings.append(embedder.doc_embed(tokenized[i:i+batch_size]))\n",
    "\n",
    "embeddings = np.concatenate(embeddings)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO NOT RUN WITHOUT CHECKING THE SAVE FILENAME.\n",
    "pickle.dump(embeddings, open('data/t_embeddings.pkl', 'wb'))\n",
    "np.save('data/t_embeddings.npy', embeddings)\n",
    "np.savetxt('data/t_embeddings.txt', embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pickle.load(open('data/t_embeddings.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 3115.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 3008.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 62.67it/s]\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0301 23:04:12.295218 11940 deprecation_wrapper.py:119] From C:\\Users\\spark\\PycharmProjects\\capstone\\embedder\\embedder.py:30: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0301 23:04:13.721509 11940 deprecation_wrapper.py:119] From C:\\Users\\spark\\PycharmProjects\\capstone\\embedder\\embedder.py:31: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W0301 23:04:14.330683 11940 deprecation_wrapper.py:119] From C:\\Users\\spark\\PycharmProjects\\capstone\\embedder\\embedder.py:32: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "q = [\n",
    "        'We advocate using the recurrent neural network transducer (RNN-T), first described in , as a more natural model for speech recognition. The RNN-T consists of two components, a transcription or encoder network and a recurrent prediction or decoder network.',\n",
    "        'Papa John\\'s has a new rewards program where you can earn free points for free pizza 5x faster and exclusive offers!',\n",
    "        'A Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. The pre-processing required in a ConvNet is much lower as compared to other classification algorithms. While in primitive methods filters are hand-engineered, with enough training, ConvNets have the ability to learn these filters/characteristics.'\n",
    "    ]\n",
    "\n",
    "qp = embedder.preprocess(q)\n",
    "qt = embedder.doc_tokenize(q)\n",
    "qe = embedder.doc_embed(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(embeddings.shape) != 2:\n",
    "    embeddings = embeddings.reshape(-1,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307 0.8562078218616183 https://en.wikipedia.org/wiki/Long_short-term_memory\n",
      "394 0.8440139867615654 https://en.wikipedia.org/wiki/Neural_network\n",
      "757 0.8409550977824336 https://en.wikipedia.org/wiki/Feedforward_neural_network\n",
      "398 0.8402388880231688 https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n",
      "129 0.8401017098735793 https://en.wikipedia.org/wiki/Convolutional_neural_network\n",
      "522 0.8359023014867027 https://en.wikipedia.org/wiki/ADALINE\n",
      "383 0.8349015862436697 https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks\n",
      "232 0.8336328560599863 https://en.wikipedia.org/wiki/Recurrent_neural_network\n",
      "495 0.8284063522383736 https://en.wikipedia.org/wiki/Multilayer_perceptron\n",
      "237 0.8264054034019389 https://en.wikipedia.org/wiki/Neural_Turing_machine\n",
      "552 0.8204692283856505 https://en.wikipedia.org/wiki/Non-negative_matrix_factorization\n",
      "324 0.8194919599246133 https://en.wikipedia.org/wiki/Capsule_neural_network\n",
      "480 0.8171801757380083 https://en.wikipedia.org/wiki/Multiple_discriminant_analysis\n",
      "730 0.8093915932111793 https://en.wikipedia.org/wiki/Linear_predictive_coding\n",
      "29 0.8084719831560259 https://en.wikipedia.org/wiki/Dynamic_time_warping\n",
      "20 0.8077749494327778 https://en.wikipedia.org/wiki/Discrete_cosine_transform\n",
      "262 0.8072507897408332 https://en.wikipedia.org/wiki/Linear_filter\n",
      "460 0.8045838412334312 https://en.wikipedia.org/wiki/Viterbi_algorithm\n",
      "776 0.8029943432639579 https://en.wikipedia.org/wiki/Independent_component_analysis\n",
      "131 0.8020830363309976 https://en.wikipedia.org/wiki/Heaviside_step_function\n",
      "195 0.8020078582410968 https://en.wikipedia.org/wiki/Boltzmann_machine\n",
      "721 0.801938295926504 https://en.wikipedia.org/wiki/Radial_basis_function_network\n",
      "617 0.8018026771541469 https://en.wikipedia.org/wiki/Cross-entropy_method\n",
      "169 0.7989065874516857 https://en.wikipedia.org/wiki/Siamese_neural_network\n",
      "462 0.7983441727933707 https://en.wikipedia.org/wiki/Hyperparameter_optimization\n",
      "\n",
      "426 0.5549668284252322 https://en.wikipedia.org/wiki/Model_selection\n",
      "278 0.5423548905376653 https://en.wikipedia.org/wiki/Virtual_assistant\n",
      "5 0.5392801290493976 https://en.wikipedia.org/wiki/Recommender_system#Content-based_filtering\n",
      "252 0.5360619329576 https://en.wikipedia.org/wiki/Chatbot\n",
      "281 0.5249545328038483 https://en.wikipedia.org/wiki/Online_chat\n",
      "805 0.5248519925940868 https://en.wikipedia.org/wiki/Ball_tree\n",
      "327 0.5236297754768189 https://en.wikipedia.org/wiki/Association_rule_learning\n",
      "663 0.5228445771283238 https://en.wikipedia.org/wiki/Vowpal_Wabbit\n",
      "247 0.5210155674962837 https://en.wikipedia.org/wiki/Lazy_learning\n",
      "825 0.5164307788173933 https://en.wikipedia.org/wiki/Beam_stack_search\n",
      "639 0.5125430300604668 https://en.wikipedia.org/wiki/Tag_(metadata)\n",
      "381 0.5099673911133735 https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Leave-one-out_cross-validation\n",
      "158 0.5077070942636286 https://en.wikipedia.org/wiki/Association_rule_learning#FP-growth_algorithm\n",
      "706 0.5039846461564261 https://en.wikipedia.org/wiki/Collaborative_search_engine\n",
      "13 0.5034524943577638 https://en.wikipedia.org/wiki/Search_algorithm\n",
      "809 0.5026885597341121 https://en.wikipedia.org/wiki/Scikit-learn\n",
      "197 0.501004007089564 https://en.wikipedia.org/wiki/Automatic_label_placement\n",
      "479 0.49848210490419026 https://en.wikipedia.org/wiki/ImageNet\n",
      "746 0.49421337848864816 https://en.wikipedia.org/wiki/Automatic_summarization\n",
      "871 0.4909320883097508 https://en.wikipedia.org/wiki/Isotonic_regression\n",
      "696 0.4906336385069404 https://en.wikipedia.org/wiki/XGBoost\n",
      "638 0.48949164510446175 https://en.wikipedia.org/wiki/Balanced_clustering\n",
      "751 0.4891217592130918 https://en.wikipedia.org/wiki/Apriori_algorithm\n",
      "591 0.48831143861945703 https://en.wikipedia.org/wiki/Noise_(signal_processing)\n",
      "418 0.48529414368776486 https://en.wikipedia.org/wiki/Hit_rate\n",
      "\n",
      "366 0.9132678005649311 https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)\n",
      "129 0.9058209505006893 https://en.wikipedia.org/wiki/Convolutional_neural_network\n",
      "545 0.8973661782965674 https://en.wikipedia.org/wiki/Winnow_(algorithm)\n",
      "462 0.8962136254899136 https://en.wikipedia.org/wiki/Hyperparameter_optimization\n",
      "52 0.8956880923617024 https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets\n",
      "354 0.8956361687516301 https://en.wikipedia.org/wiki/Extreme_learning_machine\n",
      "237 0.8950289503533446 https://en.wikipedia.org/wiki/Neural_Turing_machine\n",
      "169 0.8940814722804376 https://en.wikipedia.org/wiki/Siamese_neural_network\n",
      "342 0.8931131975147402 https://en.wikipedia.org/wiki/Limited-memory_BFGS\n",
      "427 0.8929881809512197 https://en.wikipedia.org/wiki/Feature_extraction\n",
      "341 0.8929398040493159 https://en.wikipedia.org/wiki/Kernel_methods_for_vector_output\n",
      "491 0.8924120123549011 https://en.wikipedia.org/wiki/Multidimensional_scaling\n",
      "343 0.8916366784089346 https://en.wikipedia.org/wiki/Relevance_vector_machine\n",
      "324 0.8909860259808197 https://en.wikipedia.org/wiki/Capsule_neural_network\n",
      "485 0.8909337518401634 https://en.wikipedia.org/wiki/Supervised_learning\n",
      "253 0.8901298388922094 https://en.wikipedia.org/wiki/Matrix-free_methods\n",
      "406 0.889950745231649 https://en.wikipedia.org/wiki/Autoencoder\n",
      "201 0.8889655833828383 https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search\n",
      "2 0.8879047996507503 https://en.wikipedia.org/wiki/Deep_learning#Deep_neural_networks\n",
      "183 0.8868684505065358 https://en.wikipedia.org/wiki/Graph_kernel\n",
      "269 0.8867642731187046 https://en.wikipedia.org/wiki/Manifold_regularization\n",
      "207 0.88624873566481 https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine\n",
      "142 0.8860868969940514 https://en.wikipedia.org/wiki/Speeded_up_robust_features\n",
      "667 0.8855536282938746 https://en.wikipedia.org/wiki/Mixture_of_experts\n",
      "307 0.884918399188572 https://en.wikipedia.org/wiki/Long_short-term_memory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "concepts = df.Concept.values\n",
    "for ix in range(len(qe)):\n",
    "    cosine_similarities = pd.Series(cosine_similarity(qe[ix].reshape(1,-1), embeddings).flatten())\n",
    "    output =\"\"\n",
    "    for i,j in cosine_similarities.nlargest(25).iteritems():\n",
    "        print(str(i), str(j), concepts[i])\n",
    "\n",
    "    print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
